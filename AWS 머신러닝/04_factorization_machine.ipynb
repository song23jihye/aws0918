{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52888cd",
   "metadata": {},
   "source": [
    "### Recommendation System on Amazon SageMaker - Beginner (Factorization Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702a38f",
   "metadata": {},
   "source": [
    "이 노트북에서는 Amazon Sagemaker를 사용하여 Factorization machine 으로 간단한 영화 추천 모델을 구축합니다.\n",
    "\n",
    "SageMaker built-in 알고리즘으로서의 Factorization machine 에 대한 자세한 정보는 [여기](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html) 에서 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231ae4d",
   "metadata": {},
   "source": [
    "### Factorization Machine\n",
    "https://supkoon.tistory.com/31  \n",
    "Factorization Machine (FM) 은 2010년에 도입된 지도 학습 기술입니다 ([연구 논문](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)). FM은 행렬 인수 분해를 통해 문제 차원을 줄이는 능력에서 이름을 얻었습니다.\n",
    "\n",
    "FM 은 분류 또는 회귀에 사용할 수 있으며 대규모 희소 데이터 세트에서 선형 회귀와 같은 기존 알고리즘보다 훨씬 계산 효율적입니다. 바로 이 속성이 FM 이 추천을 위해 널리 사용되는 이유입니다. 실제 추천 수는 매우 적지 만 사용자 수와 항목 수는 일반적으로 매우 큽니다 (사용자가 사용 가능한 모든 아이템을 평가하지는 않음).\n",
    "\n",
    "다음은 FM 이 데이터셋에서 어떻게 피쳐 벡터가 생성되는지를 보여주는 간단한 예입니다. 한 행(row) 에는 하나의 user 와 movie 에 대한 정보가 들어가 있는것을 확인할 수 있습니다. 각 영화 섹션에 대한 평점은 (주황색, 노랑색, 빨간색) 각 열의 합이 1이 되도록 Normalize 되어 있습니다. 마지막 Last movie rated 섹션은 주황색 섹션의 평점 바로 이전에 평점을 준 아이템이 무엇인지 알려줍니다.\n",
    "\n",
    "<!-- ![image](https://yudong-public-data.s3.ap-northeast-2.amazonaws.com/imgs/fm/fm.jpeg) -->\n",
    "\n",
    "<div>\n",
    "<img src=\"fm.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f70445",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c96130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3dbb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()                     \n",
    "prefix = 'sagemaker/movielens'\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e60d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d308f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagemaker session : <sagemaker.session.Session object at 0x7f3826b2c910>\n",
      "S3 bucket : sagemaker-us-east-1-654304825407\n",
      "Prefix : sagemaker/movielens\n",
      "Region selected : us-east-1\n",
      "IAM role : arn:aws:iam::654304825407:role/service-role/AmazonSageMaker-ExecutionRole-20230515T214643\n"
     ]
    }
   ],
   "source": [
    "print('Sagemaker session :', sess)\n",
    "print('S3 bucket :', bucket)\n",
    "print('Prefix :', prefix)\n",
    "print('Region selected :', region)\n",
    "print('IAM role :', role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac605419",
   "metadata": {},
   "source": [
    "### Build training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1531054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbUsers=943\n",
    "nbMovies=1682\n",
    "nbFeatures=nbUsers+nbMovies\n",
    "\n",
    "nbRatingsTrain=90570\n",
    "nbRatingsTest=9430"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd2f5e",
   "metadata": {},
   "source": [
    "### Dataset - MovieLens\n",
    "\n",
    "이 데이터 셋은 추천 시스템에 사용되기 좋은 데이터 셋입니다. 다양한 크기로 제공되는데 이 예제에서는 ml100k: 1682편의 영화에서 943명의 사용자가 제공하는 100,000개의 평점을 사용할 것입니다. 보시다시피 ml100k 등급 행렬은 가능한 1,586,126 (943 by 1682) 중 100,000개의 등급만 보유하기 때문에 매우 스파스되어 있습니다. (정확하게는 93.6%).\n",
    "\n",
    "다음은 데이터 세트의 처음 10개 줄입니다. 예를 들면, 사용자 754가 영화 595에 2성급 등급을 부여했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458184e8",
   "metadata": {},
   "source": [
    "\n",
    "| user id | movie id | rating | timestamp |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| 754 |       595 |        2        |     879452073 |\n",
    "| 932 |         157 |         4 |             891250667 |\n",
    "|751|         100|         4|             889132252|\n",
    "|101|         820|         3|             877136954|\n",
    "|606|         1277|      3|             878148493|\n",
    "|581|         475 |        4|             879641850|\n",
    "|13|           50|           5|             882140001|\n",
    "|457|         59|           5|             882397575|\n",
    "|111|         321|         3|             891680076|\n",
    "|123|         657|         4|             879872066|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc57f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c38da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4808k  100 4808k    0     0  11.7M      0 --:--:-- --:--:-- --:--:-- 11.7M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o data/ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ff8669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!cd data && unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbcedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5ad98",
   "metadata": {},
   "source": [
    "#### Explore data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ab97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0409c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('./data/ml-100k/ua.base', delimiter='\\t', names=[\"user-id\", \"movie-id\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b250f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>movie-id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90565</th>\n",
       "      <td>943</td>\n",
       "      <td>1047</td>\n",
       "      <td>2</td>\n",
       "      <td>875502146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90566</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90567</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90568</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90569</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user-id  movie-id  rating  timestamp\n",
       "0            1         1       5  874965758\n",
       "1            1         2       3  876893171\n",
       "2            1         3       4  878542960\n",
       "3            1         4       3  876893119\n",
       "4            1         5       3  889751712\n",
       "...        ...       ...     ...        ...\n",
       "90565      943      1047       2  875502146\n",
       "90566      943      1074       4  888640250\n",
       "90567      943      1188       3  888640250\n",
       "90568      943      1228       3  888640275\n",
       "90569      943      1330       3  888692465\n",
       "\n",
       "[90570 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f902fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./data/ml-100k/u.user', sep='|', names=u_cols,\n",
    "                    encoding='latin-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./data/ml-100k/u.data', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1')\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv('./data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(5),\n",
    "                     encoding='latin-1')\n",
    "\n",
    "# create one merged DataFrame\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "lens = pd.merge(movie_ratings, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb41e8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>308</td>\n",
       "      <td>4</td>\n",
       "      <td>887736532</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>retired</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>308</td>\n",
       "      <td>5</td>\n",
       "      <td>887737890</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>retired</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>308</td>\n",
       "      <td>4</td>\n",
       "      <td>887739608</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>retired</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
       "      <td>308</td>\n",
       "      <td>4</td>\n",
       "      <td>887738847</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>retired</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
       "      <td>308</td>\n",
       "      <td>5</td>\n",
       "      <td>887736696</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>retired</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                  title release_date  video_release_date  \\\n",
       "0         1       Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         4      Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "2         5         Copycat (1995)  01-Jan-1995                 NaN   \n",
       "3         7  Twelve Monkeys (1995)  01-Jan-1995                 NaN   \n",
       "4         8            Babe (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            imdb_url  user_id  rating  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...      308       4   \n",
       "1  http://us.imdb.com/M/title-exact?Get%20Shorty%...      308       5   \n",
       "2  http://us.imdb.com/M/title-exact?Copycat%20(1995)      308       4   \n",
       "3  http://us.imdb.com/M/title-exact?Twelve%20Monk...      308       4   \n",
       "4     http://us.imdb.com/M/title-exact?Babe%20(1995)      308       5   \n",
       "\n",
       "   unix_timestamp  age sex occupation zip_code  \n",
       "0       887736532   60   M    retired    95076  \n",
       "1       887737890   60   M    retired    95076  \n",
       "2       887739608   60   M    retired    95076  \n",
       "3       887738847   60   M    retired    95076  \n",
       "4       887736696   60   M    retired    95076  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37665143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Star Wars (1977)                             583\n",
       "Contact (1997)                               509\n",
       "Fargo (1996)                                 508\n",
       "Return of the Jedi (1983)                    507\n",
       "Liar Liar (1997)                             485\n",
       "English Patient, The (1996)                  481\n",
       "Scream (1996)                                478\n",
       "Toy Story (1995)                             452\n",
       "Air Force One (1997)                         431\n",
       "Independence Day (ID4) (1996)                429\n",
       "Raiders of the Lost Ark (1981)               420\n",
       "Godfather, The (1972)                        413\n",
       "Pulp Fiction (1994)                          394\n",
       "Twelve Monkeys (1995)                        392\n",
       "Silence of the Lambs, The (1991)             390\n",
       "Jerry Maguire (1996)                         384\n",
       "Chasing Amy (1997)                           379\n",
       "Rock, The (1996)                             378\n",
       "Empire Strikes Back, The (1980)              367\n",
       "Star Trek: First Contact (1996)              365\n",
       "Titanic (1997)                               350\n",
       "Back to the Future (1985)                    350\n",
       "Mission: Impossible (1996)                   344\n",
       "Fugitive, The (1993)                         336\n",
       "Indiana Jones and the Last Crusade (1989)    331\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated = lens.groupby('title').size().sort_values(ascending=False)[:25]\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cade319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Til There Was You (1997)</th>\n",
       "      <td>9</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-900 (1994)</th>\n",
       "      <td>5</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101 Dalmatians (1996)</th>\n",
       "      <td>109</td>\n",
       "      <td>2.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <td>125</td>\n",
       "      <td>4.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187 (1997)</th>\n",
       "      <td>41</td>\n",
       "      <td>3.024390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          rating          \n",
       "                            size      mean\n",
       "title                                     \n",
       "'Til There Was You (1997)      9  2.333333\n",
       "1-900 (1994)                   5  2.600000\n",
       "101 Dalmatians (1996)        109  2.908257\n",
       "12 Angry Men (1957)          125  4.344000\n",
       "187 (1997)                    41  3.024390"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_stats = lens.groupby('title').agg({'rating': [np.size, np.mean]})\n",
    "movie_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35293d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>They Made Me a Criminal (1939)</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlene Dietrich: Shadow and Light (1996)</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saint of Fort Washington, The (1993)</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Someone Else's America (1995)</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Kid (1997)</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           rating     \n",
       "                                             size mean\n",
       "title                                                 \n",
       "They Made Me a Criminal (1939)                  1  5.0\n",
       "Marlene Dietrich: Shadow and Light (1996)       1  5.0\n",
       "Saint of Fort Washington, The (1993)            2  5.0\n",
       "Someone Else's America (1995)                   1  5.0\n",
       "Star Kid (1997)                                 3  5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by rating average\n",
    "movie_stats.sort_values([('rating', 'mean')], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70304cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Star Wars (1977)</th>\n",
       "      <td>583</td>\n",
       "      <td>4.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silence of the Lambs, The (1991)</th>\n",
       "      <td>390</td>\n",
       "      <td>4.289744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>413</td>\n",
       "      <td>4.283293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raiders of the Lost Ark (1981)</th>\n",
       "      <td>420</td>\n",
       "      <td>4.252381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titanic (1997)</th>\n",
       "      <td>350</td>\n",
       "      <td>4.245714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empire Strikes Back, The (1980)</th>\n",
       "      <td>367</td>\n",
       "      <td>4.204360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Princess Bride, The (1987)</th>\n",
       "      <td>324</td>\n",
       "      <td>4.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fargo (1996)</th>\n",
       "      <td>508</td>\n",
       "      <td>4.155512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monty Python and the Holy Grail (1974)</th>\n",
       "      <td>316</td>\n",
       "      <td>4.066456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulp Fiction (1994)</th>\n",
       "      <td>394</td>\n",
       "      <td>4.060914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fugitive, The (1993)</th>\n",
       "      <td>336</td>\n",
       "      <td>4.044643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return of the Jedi (1983)</th>\n",
       "      <td>507</td>\n",
       "      <td>4.007890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminator, The (1984)</th>\n",
       "      <td>301</td>\n",
       "      <td>3.933555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana Jones and the Last Crusade (1989)</th>\n",
       "      <td>331</td>\n",
       "      <td>3.930514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Monty, The (1997)</th>\n",
       "      <td>315</td>\n",
       "      <td>3.926984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          rating          \n",
       "                                            size      mean\n",
       "title                                                     \n",
       "Star Wars (1977)                             583  4.358491\n",
       "Silence of the Lambs, The (1991)             390  4.289744\n",
       "Godfather, The (1972)                        413  4.283293\n",
       "Raiders of the Lost Ark (1981)               420  4.252381\n",
       "Titanic (1997)                               350  4.245714\n",
       "Empire Strikes Back, The (1980)              367  4.204360\n",
       "Princess Bride, The (1987)                   324  4.172840\n",
       "Fargo (1996)                                 508  4.155512\n",
       "Monty Python and the Holy Grail (1974)       316  4.066456\n",
       "Pulp Fiction (1994)                          394  4.060914\n",
       "Fugitive, The (1993)                         336  4.044643\n",
       "Return of the Jedi (1983)                    507  4.007890\n",
       "Terminator, The (1984)                       301  3.933555\n",
       "Indiana Jones and the Last Crusade (1989)    331  3.930514\n",
       "Full Monty, The (1997)                       315  3.926984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atleast_100 = movie_stats['rating']['size'] >= 300\n",
    "movie_stats[atleast_100].sort_values([('rating', 'mean')], ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9755812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "users.age.plot.hist(bins=30)\n",
    "plt.title(\"Distribution of users' ages\")\n",
    "plt.ylabel('count of users')\n",
    "plt.xlabel('age');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422f2e9",
   "metadata": {},
   "source": [
    "### Data set preparation\n",
    "\n",
    "앞에서 설명한 것처럼 FM은 고차원 데이터 세트에서 가장 잘 작동합니다. 결과적으로 사용자 ID와 영화 ID를 한 번에 인코딩할 것입니다 (타임스탬프는 무시하겠습니다). 따라서 데이터 세트의 각 샘플은 사용자 ID 및 동영상 ID와 관련하여 두 개의 값만 1로 설정된 2,625 Boolean 벡터 (943+1682) 가 됩니다.\n",
    "\n",
    "바이너리 추천자를 만들 것입니다 (즉, 좋아요/마음에 들지 않음). 4 성급 및 5 성급 등급은 1로 설정됩니다.낮은 등급은 0으로 설정됩니다.\n",
    "\n",
    "마지막으로, Amazon SageMaker에서 FM을 구현하려면 훈련 및 테스트 데이터를 protobuf 형식의 float32 텐서에 저장해야 한다는 것입니다.(예, 복잡하게 들립니다 🙂 그러나 Amazon SageMaker SDK는 이를 처리하는 편리한 유틸리티 기능을 제공하므로 너무 걱정하지 마십시오.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2917a01",
   "metadata": {},
   "source": [
    "### Highlevel Overview\n",
    "\n",
    "구현해야 할 단계는 다음과 같습니다.\n",
    "\n",
    "* 디스크에서 MovieLens 훈련 세트와 테스트 세트를 로드합니다.\n",
    "* 각 세트에 대해 핫 인코딩된 데이터 샘플을 포함하는 sparse 행렬을 만듭니다.\n",
    "* 각 세트에 대해 등급을 유지하는 레이블 벡터를 만듭니다.\n",
    "* 두 세트를 모두 protobuf로 인코딩된 파일에 씁니다.\n",
    "* 이러한 파일을 Amazon S3 버킷에 복사합니다.\n",
    "* Amazon SageMaker에서 FM training 작업을 구성하고 실행합니다.\n",
    "* 해당 모델을 엔드포인트에 배포합니다.\n",
    "* 몇 가지 예측을 실행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58869c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user, build a list of rated movies.\n",
    "# We'd need this to add random negative samples.\n",
    "moviesByUser = {}\n",
    "for userId in range(nbUsers):\n",
    "    moviesByUser[str(userId)]=[]\n",
    "\n",
    "with open('./data/ml-100k/ua.base','r') as f:\n",
    "    samples=csv.reader(f,delimiter='\\t')\n",
    "    for userId,movieId,rating,timestamp in samples:\n",
    "        moviesByUser[str(int(userId)-1)].append(int(movieId)-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "554fae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, lines, columns):\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    # Labels are stored in a vector\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter='\\t')\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(nbUsers)+int(movieId)-1] = 1\n",
    "            if int(rating) >= 4:\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "            line=line+1\n",
    "            \n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14745d7b",
   "metadata": {},
   "source": [
    "* A training sparse matrix: 90,570 행과 2,625 열 (user ID 에 관련된 943 개의 원-핫 인코딩이 된 피쳐들과, movie ID 와 관련된 1682개의 원-핫 인코딩이 된 피쳐들)\n",
    "* A training label array: 90,570 개의 등급\n",
    "* A test sparse matrix: 9,430 개의 행과 2,625 열\n",
    "* A test label array: 9,430 개의 등급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "627e162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = loadDataset('./data/ml-100k/ua.base', nbRatingsTrain, nbFeatures)\n",
    "X_test, Y_test = loadDataset('./data/ml-100k/ua.test',nbRatingsTest,nbFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a47400e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2625)\n",
      "(90570,)\n",
      "Training labels: 49906 zeros, 40664 ones\n",
      "(9430, 2625)\n",
      "(9430,)\n",
      "Test labels: 5469 zeros, 3961 ones\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "assert X_train.shape == (nbRatingsTrain, nbFeatures)\n",
    "assert Y_train.shape == (nbRatingsTrain, )\n",
    "zero_labels = np.count_nonzero(Y_train)\n",
    "print(\"Training labels: %d zeros, %d ones\" % (zero_labels, nbRatingsTrain-zero_labels))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "assert X_test.shape  == (nbRatingsTest, nbFeatures)\n",
    "assert Y_test.shape  == (nbRatingsTest, )\n",
    "zero_labels = np.count_nonzero(Y_test)\n",
    "print(\"Test labels: %d zeros, %d ones\" % (zero_labels, nbRatingsTest-zero_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe1a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train3')\n",
    "\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test3')\n",
    "\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b39e91",
   "metadata": {},
   "source": [
    "### Convert to protobuf and save to S3\n",
    "\n",
    "다음으로 train 세트와 test 세트를 Amazon S3 에 저장된 두 개의 protobuf 파일로 작성하겠습니다. 다행스럽게도 write_spmatrix_to_sparse_tensor() 유틸리티 함수를 사용할 수 있습니다. 샘플과 레이블을 인 메모리 protobuf 로 인코딩된 sparse 다차원 배열 (일명 텐서) 에 씁니다.\n",
    "\n",
    "그런 다음 버퍼를 Amazon S3에 커밋합니다. 이 단계가 완료되면 데이터 준비가 완료되었으며 이제 training 작업에 집중할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "874fd65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-654304825407/sagemaker/movielens/train3/train.protobuf\n",
      "s3://sagemaker-us-east-1-654304825407/sagemaker/movielens/test3/test.protobuf\n",
      "Output: s3://sagemaker-us-east-1-654304825407/sagemaker/movielens/output\n"
     ]
    }
   ],
   "source": [
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "test_data  = writeDatasetToProtobuf(X_test, Y_test, bucket, test_prefix, test_key)    \n",
    "  \n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eefed0",
   "metadata": {},
   "source": [
    "### Run training job\n",
    "\n",
    "AWS 리전에서 사용할 수 있는 FM 컨테이너를 기반으로 Estimator를 만드는 것부터 시작하겠습니다. 그런 다음 FM 전용 하이퍼파라미터([참조](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/fact-machines-hyperparameters.html))를 설정해야 합니다.\n",
    "\n",
    "feature_dim: 각 샘플의 피처 수입니다 (이 경우 2,625개).\n",
    "predictor_type: 'binary_classifier'를 사용할 것입니다.\n",
    "num_factors: 사용자 및 항목 행렬의 공통 차원입니다 (게시물 시작 부분의 예제에서 설명).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e510f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "container = image_uris.retrieve('factorization-machines', region=sess.boto_region_name, version='latest')\n",
    "# container = sagemaker.amazon.amazon_estimator.get_image_uri(\n",
    "#     boto3.Session().region_name, \"factorization-machines\", \"latest\")\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "293f1ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: factorization-machines-2023-05-20-14-06-23-906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20 14:06:26 Starting - Starting the training job...\n",
      "2023-05-20 14:06:52 Starting - Preparing the instances for training.........\n",
      "2023-05-20 14:08:24 Downloading - Downloading input data...\n",
      "2023-05-20 14:08:49 Training - Downloading the training image...............\n",
      "2023-05-20 14:11:25 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '10', 'feature_dim': '2625', 'mini_batch_size': '1000', 'num_factors': '64', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Final configuration: {'epochs': '10', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2625', 'num_factors': '64', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 WARNING 140542589814592] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:46.618] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:46.622] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591906.6143508, \"EndTime\": 1684591906.6578145, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 36.38815879821777, \"count\": 1, \"min\": 36.38815879821777, \"max\": 36.38815879821777}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591906.6579778, \"EndTime\": 1684591906.6580188, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[14:11:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.207.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[14:11:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.207.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[14:11:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.207.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.558\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.6920031127929688\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:46 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_f_1.000 <score>=0.6769005847953217\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:47.217] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 539, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.5575054945054945\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.6897803136804601\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=0, train binary_f_1.000 <score>=0.6986657087907565\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591906.6579075, \"EndTime\": 1684591907.2183836, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"update.time\": {\"sum\": 560.053825378418, \"count\": 1, \"min\": 560.053825378418, \"max\": 560.053825378418}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591906.658294, \"EndTime\": 1684591907.218688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 91570.0, \"count\": 1, \"min\": 91570, \"max\": 91570}, \"Total Batches Seen\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=161579.16613711245 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.587\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.6713773193359375\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_f_1.000 <score>=0.739760554505356\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:47.800] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 577, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.5637912087912088\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.6830939056061126\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=1, train binary_f_1.000 <score>=0.7029728900561953\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591907.2184963, \"EndTime\": 1684591907.8024006, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 582.7920436859131, \"count\": 1, \"min\": 582.7920436859131, \"max\": 582.7920436859131}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591907.219575, \"EndTime\": 1684591907.8029356, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 182140.0, \"count\": 1, \"min\": 182140, \"max\": 182140}, \"Total Batches Seen\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=155210.6693687436 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.587\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.6648751220703125\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:47 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_f_1.000 <score>=0.739760554505356\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:48.420] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 612, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.5742967032967033\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.6779770058432778\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=2, train binary_f_1.000 <score>=0.7068403169293871\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591907.8024948, \"EndTime\": 1684591908.4211178, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 617.4087524414062, \"count\": 1, \"min\": 617.4087524414062, \"max\": 617.4087524414062}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591907.8036735, \"EndTime\": 1684591908.4214225, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 272710.0, \"count\": 1, \"min\": 272710, \"max\": 272710}, \"Total Batches Seen\": {\"sum\": 274.0, \"count\": 1, \"min\": 274, \"max\": 274}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=146573.40833097327 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.587\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.659190673828125\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:48 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_f_1.000 <score>=0.739760554505356\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:49.039] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 615, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.5849340659340659\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.6734385335733603\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=3, train binary_f_1.000 <score>=0.709808772347667\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591908.4212158, \"EndTime\": 1684591909.0411305, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 618.9005374908447, \"count\": 1, \"min\": 618.9005374908447, \"max\": 618.9005374908447}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591908.4221926, \"EndTime\": 1684591909.0415938, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 363280.0, \"count\": 1, \"min\": 363280, \"max\": 363280}, \"Total Batches Seen\": {\"sum\": 365.0, \"count\": 1, \"min\": 365, \"max\": 365}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=146160.25892517733 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.587\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.6542156982421875\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_f_1.000 <score>=0.739760554505356\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:49.630] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 584, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.5937362637362638\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.6694205201536745\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=4, train binary_f_1.000 <score>=0.7119370422315724\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591909.0412886, \"EndTime\": 1684591909.6320107, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 589.3752574920654, \"count\": 1, \"min\": 589.3752574920654, \"max\": 589.3752574920654}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591909.0426004, \"EndTime\": 1684591909.6324275, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453850.0, \"count\": 1, \"min\": 453850, \"max\": 453850}, \"Total Batches Seen\": {\"sum\": 456.0, \"count\": 1, \"min\": 456, \"max\": 456}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=153495.16103980274 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_accuracy <score>=0.588\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_cross_entropy <loss>=0.6498548583984375\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:49 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_f_1.000 <score>=0.73989898989899\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:50.233] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 596, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, train binary_classification_accuracy <score>=0.6005934065934065\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy <loss>=0.6658505363045158\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=5, train binary_f_1.000 <score>=0.7134726054394954\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591909.632167, \"EndTime\": 1684591910.2344267, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 600.933313369751, \"count\": 1, \"min\": 600.933313369751, \"max\": 600.933313369751}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591909.6334448, \"EndTime\": 1684591910.2347248, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 544420.0, \"count\": 1, \"min\": 544420, \"max\": 544420}, \"Total Batches Seen\": {\"sum\": 547.0, \"count\": 1, \"min\": 547, \"max\": 547}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=150586.68897121842 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_accuracy <score>=0.594\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_cross_entropy <loss>=0.646020751953125\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_f_1.000 <score>=0.7420584498094028\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:50.722] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 485, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, train binary_classification_accuracy <score>=0.607956043956044\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy <loss>=0.6626614212203812\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=6, train binary_f_1.000 <score>=0.7159056522639315\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591910.234522, \"EndTime\": 1684591910.7241828, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 488.7363910675049, \"count\": 1, \"min\": 488.7363910675049, \"max\": 488.7363910675049}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591910.235414, \"EndTime\": 1684591910.7246141, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634990.0, \"count\": 1, \"min\": 634990, \"max\": 634990}, \"Total Batches Seen\": {\"sum\": 638.0, \"count\": 1, \"min\": 638, \"max\": 638}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=185084.83662971252 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_accuracy <score>=0.612\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_cross_entropy <loss>=0.6426356201171874\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:50 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_f_1.000 <score>=0.7503217503217503\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:51.232] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 504, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, train binary_classification_accuracy <score>=0.6152637362637363\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy <loss>=0.6597937990964114\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=7, train binary_f_1.000 <score>=0.71838678281573\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591910.7242935, \"EndTime\": 1684591911.233349, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 508.04829597473145, \"count\": 1, \"min\": 508.04829597473145, \"max\": 508.04829597473145}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591910.7252712, \"EndTime\": 1684591911.2336652, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 725560.0, \"count\": 1, \"min\": 725560, \"max\": 725560}, \"Total Batches Seen\": {\"sum\": 729.0, \"count\": 1, \"min\": 729, \"max\": 729}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=178092.4367908885 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_accuracy <score>=0.623\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_cross_entropy <loss>=0.639631103515625\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_f_1.000 <score>=0.7547169811320755\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:51.722] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 485, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, train binary_classification_accuracy <score>=0.622956043956044\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy <loss>=0.6571962018694196\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=8, train binary_f_1.000 <score>=0.7211100002438489\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591911.2334635, \"EndTime\": 1684591911.7234626, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 488.9390468597412, \"count\": 1, \"min\": 488.9390468597412, \"max\": 488.9390468597412}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591911.2344904, \"EndTime\": 1684591911.723751, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 816130.0, \"count\": 1, \"min\": 816130, \"max\": 816130}, \"Total Batches Seen\": {\"sum\": 820.0, \"count\": 1, \"min\": 820, \"max\": 820}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=185062.65566327277 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_accuracy <score>=0.636\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_cross_entropy <loss>=0.6369479370117187\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:51 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_f_1.000 <score>=0.7608409986859396\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:52.203] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 476, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, train binary_classification_accuracy <score>=0.6306373626373626\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy <loss>=0.6548245393522493\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, epoch=9, train binary_f_1.000 <score>=0.7243336340523251\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.6306373626373626\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, train binary_classification_cross_entropy <loss>=0.6548245393522493\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.7243336340523251\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591911.7235646, \"EndTime\": 1684591912.2048395, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 480.38673400878906, \"count\": 1, \"min\": 480.38673400878906, \"max\": 480.38673400878906}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591911.7244174, \"EndTime\": 1684591912.2051437, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906700.0, \"count\": 1, \"min\": 906700, \"max\": 906700}, \"Total Batches Seen\": {\"sum\": 911.0, \"count\": 1, \"min\": 911, \"max\": 911}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #throughput_metric: host=algo-1, train throughput=188343.3178792679 records/second\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 WARNING 140542589814592] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591912.204943, \"EndTime\": 1684591912.20901, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 3.4394264221191406, \"count\": 1, \"min\": 3.4394264221191406, \"max\": 3.4394264221191406}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] Saved checkpoint to \"/tmp/tmpdbpmco0d/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:52.244] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 5626, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2023-05-20 14:11:52.280] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 35, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591912.244358, \"EndTime\": 1684591912.2801878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Total Batches Seen\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Max Records Seen Between Resets\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #test_score (algo-1) : ('binary_classification_accuracy', 0.6327677624602333)\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #test_score (algo-1) : ('binary_classification_cross_entropy', 0.6501862251872349)\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #test_score (algo-1) : ('binary_f_1.000', 0.7511676367033125)\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.6327677624602333\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=0.6501862251872349\u001b[0m\n",
      "\u001b[34m[05/20/2023 14:11:52 INFO 140542589814592] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.7511676367033125\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1684591912.209094, \"EndTime\": 1684591912.2820332, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 27.13322639465332, \"count\": 1, \"min\": 27.13322639465332, \"max\": 27.13322639465332}, \"totaltime\": {\"sum\": 5698.266983032227, \"count\": 1, \"min\": 5698.266983032227, \"max\": 5698.266983032227}}}\u001b[0m\n",
      "\n",
      "2023-05-20 14:11:55 Uploading - Uploading generated training model\n",
      "2023-05-20 14:12:11 Completed - Training job completed\n",
      "Training seconds: 228\n",
      "Billable seconds: 228\n"
     ]
    }
   ],
   "source": [
    "# 학습 : 약 6분 소요\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   get_execution_role(), \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.m4.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=nbFeatures,\n",
    "                      predictor_type='binary_classifier',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=10)\n",
    "\n",
    "fm.fit({'train': train_data, 'test': test_data})  # 정확도 : 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78c999",
   "metadata": {},
   "source": [
    "50 epoch 이후 테스트 정확도는 71.5% 이고 F1 점수 (이진 분류기의 일반적인 메트릭) 는 0.75입니다 (1은 완벽한 분류기를 나타냄) - 이는 매번 조금씩 달라질 수 있습니다. 좋지는 않지만 sparse 행렬과 protobuf 로 인해 하이퍼 파라미터를 조정하는 데 많은 시간을 소비하지 않았습니다.\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : binary_classification_accuracy\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : 0.7159\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : binary_classification_cross_entropy\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : 0.581087609863\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : binary_f_1.000\n",
    "\n",
    "[01/29/2018 13:42:41 INFO 140015814588224] #test_score (algo-1) : 0.74558968389\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7654f",
   "metadata": {},
   "source": [
    "### Deploy model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69b39bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "       js = {'instances': []}\n",
    "       for row in data:\n",
    "              js['instances'].append({'features': row.tolist()})\n",
    "       return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93f1b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: factorization-machines-2023-05-20-14-12-50-873\n",
      "INFO:sagemaker:Creating endpoint-config with name movielens-20-14-12-50\n",
      "INFO:sagemaker:Creating endpoint with name movielens-20-14-12-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "# 약 6 분 소요\n",
    "from time import strftime, gmtime\n",
    "timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "fm_predictor = fm.deploy(\n",
    "    endpoint_name = 'movielens-{}'.format(timestamp),\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    serializer=FMSerializer(),\n",
    "    deserializer= JSONDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca07aee",
   "metadata": {},
   "source": [
    "### Run predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fea2b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 0.5666278600692749, 'predicted_label': 1.0}, {'score': 0.48668694496154785, 'predicted_label': 0.0}, {'score': 0.4943739175796509, 'predicted_label': 0.0}, {'score': 0.5673641562461853, 'predicted_label': 1.0}, {'score': 0.5373562574386597, 'predicted_label': 1.0}, {'score': 0.49052491784095764, 'predicted_label': 0.0}, {'score': 0.507140040397644, 'predicted_label': 1.0}, {'score': 0.5508791208267212, 'predicted_label': 1.0}, {'score': 0.5169398784637451, 'predicted_label': 1.0}, {'score': 0.49745112657546997, 'predicted_label': 0.0}]}\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 10개 영화에 대하여 바이너리 추천(좋아요:1 /마음에 들지 않음:0)\n",
    "result = fm_predictor.predict(X_test[1000:1010].toarray(), initial_args={\"ContentType\": \"application/json\"})\n",
    "print(result)\n",
    "# print (Y_test[1000:1010])  # 실제 값 : [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2b263e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 예측값 : 추천값\n",
    "pred = np.array([(k['predicted_label']) for k in result['predictions']])\n",
    "print(pred)\n",
    "print (Y_test[1000:1010])  # 실제 값 : [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3964bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: movielens-20-14-12-50\n",
      "INFO:sagemaker:Deleting endpoint with name: movielens-20-14-12-50\n"
     ]
    }
   ],
   "source": [
    "# 모델 엔드포인트 삭제\n",
    "# fm_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
